
文档中心
请输入关键字
搜索历史
智能视觉
花费
智能创作云
热门搜索
扣子
火山方舟
豆包大模型
语音合成
云服务器
文档
备案
控制台
z
zhaoweibo.0820 / eps_yxd_group
账号管理
账号ID : 2108323502
联邦登陆
企业认证
费用中心
可用余额¥ 0.00
充值汇款
账户总览
账单详情
费用分析
发票管理
权限与安全
安全设置
访问控制
操作审计
API 访问密钥
工具与其他
公测申请
资源管理
配额中心
伙伴控制台
待办事项
待支付
0
待续费
0
待处理工单
0
未读消息
0
火山方舟大模型服务平台
文档首页
/
火山方舟大模型服务平台
/
视觉理解
/
视觉理解
在本产品文档中搜索
视觉理解
最近更新时间：2025.10.17 20:02:50
首次发布时间：2024.11.07 21:54:45
我的收藏
有用
无用
部分大模型具备视觉理解能力，如当您传入图片或视频时，大模型可以理解图片或视频里的视觉信息，并结合这些信息完成如描述其中的物体等视觉相关任务。通过这篇教程，您可以学习到如何通过调用大模型 API 来识别传入图片和视频里的信息。

查看使用示例，了解常见调用方法。
查看对话(Chat) API，检索 API 字段参数说明。
查看视频理解示例，和视频理解使用说明。

支持模型
当前支持视觉理解的模型请参见视觉理解。

前提条件
获取 API Key
获取 API Key
使用 Access Key 鉴权请参考 Access Key 签名鉴权。
开通模型服务
在 模型列表 获取所需 Model ID
通过 Endpoint ID 调用模型服务，请参考 获取 Endpoint ID（创建自定义推理接入点）。

快速开始
支持视觉理解的大模型当前支持在请求中传入图片链接，图片信息需要作为用户角色输入信息传给大模型，即"role": "user"，下面是简单的视觉模型调用示例代码。

图片理解
视频理解
import os
from volcenginesdkarkruntime import Ark # 通过命令安装方舟SDK pip install 'volcengine-python-sdk[ark]'

# 初始化Ark客户端
client = Ark(
    base_url="https://ark.cn-beijing.volces.com/api/v3",    
    api_key=os.getenv('ARK_API_KEY'), # 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
)

# 创建一个对话请求
completion = client.chat.completions.create(
    # Get Model ID: https://www.volcengine.com/docs/82379/1330310
    model = "doubao-seed-1-6-251015",
    messages = [
        {
            # 指定消息的角色为用户
            "role": "user",  
            "content": [   
                # 图片信息，希望模型理解的图片
                {"type": "image_url", "image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"},},
                # 文本消息，希望模型根据图片信息回答的问题
                {"type": "text", "text": "支持输入图片的模型系列是哪个？"}, 
            ],
        }
    ],
)

print(completion.choices[0].message.content)
模型回复预览：

根据表格中的信息，支持输入图片的模型系列是 **Doubao-1.5-vision**。
说明

提示词支持图片和文字混排，但图文顺序可能对模型的输出效果产生影响。在提示词构成为多张图片+1段文字，建议将文字放在提示词最后。



使用说明
说明

处理完图片/视频后，文件会从方舟服务器删除。方舟不会保留您提交的图片、视频以及文本信息等用户数据来训练模型。


图片理解

图片传入方式
图片 URL 或 Base64 编码。用图片 URL 方式时，需确保图片 URL 可被访问。

说明

如果您希望获得更低的时延和成本，建议使用TOS（火山引擎对象存储）存储图片并生成访问链接。方舟与 TOS 网络打通，可使用内网通信，具备好处：

高速访问图片速度，降低模型回复的时延。
降低公网访问图片产生的流量费用。
视觉理解接口 对话(Chat) API 是无状态的，如果您需要模型多次理解同一张图片，则每次请求时都需要传入该图片信息。

图片像素说明
方舟在处理图片前会先行进行图片尺寸判断，如果图片超出下面的限制，会直接报错，传入图片满足下面条件（单位 px）：
宽 > 14 且 高>14。
宽*高范围： [196, 3600万]。
满足上述条件的图片，方舟检测图片大小并将图片等比例压缩，并根据不同模式，将图片像素处理（等比例）至下面范围。
detail:low模式下，104万（1024×1024） px；
detail:high模式下，401万（2048×1960） px。
其中
detail:low、detail:high，指低/高精度理解图像，具体说明请参见理解图像的深度控制。
说明

推荐您自行压缩或裁剪图片，可降低模型响应时延以及根据业务灵活调整，如裁剪掉图片空白或不重要部分。如自行压缩，请控制图片像素（宽×高）至上述范围。压缩图片示例：最佳实践-上传本地图片进行分析。


图片数量说明
单次请求传入图片数量受限于模型最大上下文长度（模型最大上下文长度见视觉理解能力模型）。当输入信息过长，譬如上下文长度 32k 的模型，传入 25 张图片，触发了模型上下文长度限制，信息会被截断后处理。

举例说明：

当图片总像素值大，使用模型上下文窗口限制为 32k，每个图片转为 1312 个 token ，单轮可传入的图片数量为 32000 ÷ 1312 = 24 张。
当图片总像素值小，使用模型上下文窗口限制为 32k，每个图片转为 256 个 token，单轮可传入的数量为 32000 ÷ 256 = 125 张。
说明

模型对图片理解以及内容回复的质量，受到同时处理图片信息量的影响。单次请求过多的图片张数会导致模型回复质量下滑，以及超出模型上下文限制，为了更好的回复质量，建议您合理控制传入图片的数量。


图片文件容量
单张图片小于 10 MB。
使用 base64 编码，请求中请求体大小不可超过 64 MB。

token 用量说明
token 用量，根据图片宽高像素计算可得。图片转化 token 的公式为：

min(图片宽 * 图片高÷784, 单图 token 限制)
detail:high模式下，单图 token 限制为 5120 token。
detail:low模式下，单图 token 限制为 1312 token。
图片尺寸为 1280 px × 720 px，即宽为 1280 px，高为 720 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为1280×720÷784=1176，因为小于 1312，消耗 token 数为 1176 。
图片尺寸为 1920 px × 1080 px，即宽为 1920 px，高为 1080 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为1920×1080÷784=2645，因为大于 1312，消耗 token 数为 1312 。这时会压缩 token，即图片的细节会丢失部分，譬如字体很小的图片，模型可能就无法准确识别文字内容。

图片格式说明
支持的图片格式如下表，注意文件后缀匹配图片格式，即图片文件扩展名（URL传入时）、图片格式声明（Base64 编码传入时）需与图片实际信息一致。

图片格式

文件扩展名

内容格式 Content Type

上传图片至对象存储时设置。
传入图片 Base64 编码时使用：Base64 编码输入。
图片格式指定需使用小写
JPEG

.jpg, .jpeg

image/jpeg

PNG

.png

image/png

GIF

.gif

image/gif

WEBP

.webp

image/webp

BMP

.bmp

image/bmp

TIFF

.tiff, .tif

image/tiff

ICO

.ico

image/ico

DIB

.dib

image/bmp

ICNS

.icns

image/icns

SGI

.sgi

image/sgi

JPEG2000

.j2c, .j2k, .jp2, .jpc, .jpf, .jpx

image/jp2

HEIC

.heic

image/heic

doubao-1.5-vision-pro及以后模型支持

HEIF

.heif

image/heif

doubao-1.5-vision-pro及以后模型支持

说明

TIFF、 SGI、ICNS、JPEG2000 几种格式图片，需要保证和元数据对齐，如在对象存储中正确设置文件元数据，否则会解析失败。详细见 使用视觉理解模型时，报错InvalidParameter？


API 参数字段说明
以下字段视觉理解暂不支持。

不支持设置频率惩罚系数，无 frequency_penalty 字段。
不支持设置存在惩罚系数，presence_penalty 字段。
不支持为单个请求生成多个返回，无 n 字段。

视频理解

时序信息
基于FPS的抽帧获取视频关键帧，再通过时间戳+图像拼接标记时序信息，模型基于该请求中的时序标记和图像内容，实现对视频的完整理解（包括内容变化、动作逻辑、时序关联等）。
详细原理见 附1. 视频理解时间戳拼接工作原理。

视频格式说明
视频格式

文件扩展名

内容格式 Content Type

上传视频至对象存储时设置。
传入 Base64 编码时使用：Base64 编码输入。
视频格式需小写
MP4

.mp4

video/mp4

AVI

.avi

video/avi

MOV

.mov

url传入图片：对象存储请设置 Content Type 为：video/quicktime
base64编码：请使用 video/mov，即data:video/mov;base64,<Base64编码>
因视频文件格式变种较多，不能保证所有文件都能被识别，请通过测试验证文件能够被正常识别。


视频文件容量
单视频文件需在 50MB 以内。

不支持音频理解
暂不支持对视频文件中的音频信息进行理解。

用量说明
单视频 token 用量范围在 [10k, 80k] ，单次请求视频最大 token 量还受模型的最大上下文窗口以及最大输入长度（当启用深度推理模式）限制，超出则请调整传入视频数量或视频长度。
方舟根据帧图像（某个时刻的视频画面，此处特指输入给模型的帧图像）张数（视频时长 * fps ），对帧图像进行压缩，以平衡对于视频的理解精度和 token 用量。帧图像会被等比例压缩至 [128 token, 640 token] ，对应像素范围在 [10万 像素, 50万像素]。

如fps过高或视频长度过长，需要处理的帧图像数量超出 640 帧（80×1024 token ÷ 128 token / 帧 = 640 帧），则按帧图像 128 token 视频时长/640 时间间隔均匀抽取 640帧。此时与请求中的配置不符，建议评估输出效果，按需调整视频时长或 fps 字段配置。
如fps过小或视频长度过短，需要处理的帧图像数量不足16帧（10×1024 token ÷ 640 token / 帧 = 16 帧），则按帧图像 640 token 视频时长/16 时间间隔均匀抽取 16帧。

使用示例

多图输入
API 可以支持接受和处理多个图像输入，这些图像可以通过图片可访问 URL 或图片转为 Base64 编码后输入，模型将结合所有传入的图像中的信息来回答问题。

Curl
Python
Go
Java
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json"  \
   -H "Authorization: Bearer $ARK_API_KEY"  \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [                
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"}},
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_2.png"}},
                {"type": "text", "text": "支持输入图片的模型系列是哪个？同时，豆包应用场景有哪些？"}
            ]
        }
    ],
    "max_tokens": 300
  }'

Base64 编码输入
如果你要传入的图片/视频在本地，你可以将这个其转化为 Base64 编码，然后提交给大模型。下面是一个简单的示例代码。

注意

传入 Base64 编码格式时，请遵循以下规则：

传入的是图片：
格式遵循data:image/<图片格式>;base64,<Base64编码>，其中，
图片格式：jpeg、png、gif等，支持的图片格式详细见图片格式说明。
Base64 编码：图片的 Base64 编码。
传入的是视频：
格式遵循data:video/<视频格式>;base64,<Base64编码>，其中，
视频格式：MP4、AVI等，支持的视频格式详细见视频格式说明。
Base64 编码：视频的 Base64 编码。
Curl
Python
Go
Java
BASE64_IMAGE=$(base64 < path_to_your_image.jpeg) && curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json"  \
   -H "Authorization: Bearer $ARK_API_KEY"  \
   -d @- <<EOF
   {
    "model": "doubao-seed-1-6-251015",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
              "url": "data:image/jpeg;base64,$BASE64_IMAGE"
            }
          },
          {
            "type": "text",
            "text": "图里有什么"
          }
        ]
      }
    ],
    "max_tokens": 300
  }
EOF

控制图片理解的精细度
控制图片理解的精细度（指对画面的精细）： image_pixel_limit 、detail 字段，2个字段若同时配置，则生效逻辑如下：

生效前提：图片像素范围在 [196, 3600万] px，否则直接报错。
生效优先级：image_pixel_limit 高于 detail 字段，即同时配置 detail 与 image_pixel_limit 字段时，生效 image_pixel_limit 字段配置。
缺省时逻辑：image_pixel_limit 字段的 min_pixels / max_pixels 字段未设置，则使用 detail （默认值为low）设置配置的值对应的min_pixels 值 3136 **** / max_pixels 值1048576。
下面分别介绍如何通过 detail 、 image_pixel_limit 控制视觉理解的精度。

通过 detail 字段（图片理解）
你可以通过detail参数来控制模型理解图片的精细度，返回速度，token用量，计费公式请参见token 用量说明。

low：“低分辨率”模式，默认此模式，处理速度会提高，适合图片本身细节较少或者只需要模型理解图片大致信息或者对速度有要求的场景。此时 min_pixels 取值3136、max_pixels 取值1048576，超出此像素范围且小于3600w px的图片（超出3600w px 会直接报错）将会等比例缩放至范围内。
high：“高分辨率”模式，这代表模型会理解图片更多的细节，但是处理图片速度会降低，适合需要模型理解图像细节，图像细节丰富，需要关注图片细节的场景。此时 min_pixels 取值3136、max_pixels 取值4014080，超出此像素范围且小于3600w px的图片（超出3600w px 会直接报错）的图片将会等比例缩放至范围内。
Curl
Python
Go
Java
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer $ARK_API_KEY" \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [                
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"},"detail": "high"},
                {"type": "text", "text": "支持输入图片的模型系列是哪个？"}
            ]
        }
    ],
    "max_tokens": 300
  }'

通过 image_pixel_limit 结构体
控制传入给方舟的图像像素大小范围，如果不在此范围，则会等比例放大或者缩小至该范围内，后传给模型进行理解。您可以通过 image_pixel_limit 结构体，精细控制模型可理解的图片像素多少。
对应结构体如下：

"image_pixel_limit": {
    "max_pixels": 3014080,   # 图片最大像素
    "min_pixels": 3136       # 图片最小像素
}
示例代码如下：

Curl
Python
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer $ARK_API_KEY" \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [                
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"},"image_pixel_limit": {"max_pixels": 3014080,"min_pixels": 3136}},
                {"type": "text", "text": "支持输入图片的模型系列是哪个？"}
            ]
        }
    ],
    "max_tokens": 300
  }'

控制视频理解的精细度
当前支持视频理解的模型见视觉理解能力，简单示例见 快速开始

您可通过 fps 字段，控制从视频中抽取图像的频率，默认为1，即每秒从视频中抽取一帧图像，输入给模型进行视觉理解。 可通过 fps 字段，控制模型对于视频中图像变化的敏感度。

当视频画面变化剧烈或需关注画面变化，如计算视频中角色动作次数，可调高 fps 设置（最高 5），防止抽帧频率低导致误判。
当视频画面变化不频繁或无需关注画面变化，如画面中人数，可调低 fps （最低0.2），可提升处理速度，节省 token 用量。
示例代码如下：

Curl
Python
Go
Java
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer $ARK_API_KEY" \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [                
                {"type": "video_url","video_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_video/ark_vlm_video_input.mp4"},"fps": "2"},
                {"type": "text", "text": "视频里有什么？"}
            ]
        }
    ],
    "max_tokens": 300
  }'

感知视频时序
视频理解可理解视频时间和图像关系信息，如回答事件发生什么时间点，在哪些时间发生了某事件等和时间相关的信息，原理见 附1. 视频理解时间戳拼接工作原理。
下面是简单示例代码

Curl
Python
Go
Java
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer $ARK_API_KEY" \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [                
                {"type": "video_url","video_url": {"url":  "https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ea543baf50134fe0be5ceb7031e544e1~tplv-goo7wpa0wc-image.image"},"fps": "5"},
                {"type": "text", "text": "裁判什么时间点出现的？"}
            ]
        }
    ],
    "max_tokens": 300
  }'
回复预览

根据视频描述，裁判在**3.7秒**左右出现。此时，画面中两位拳击手（左为黑T恤红短裤、右为白T恤黑短裤）原本处于对峙状态，随后裁判（穿着黑色西装、戴白手套）站到两人中间，似乎在准备开始比赛或暂停当前回合，观众仍在背景中欢呼。

使用BotChatCompletions接口
您可调用配置视觉理解模型的bot，同时配置支持的插件（联网、文件解析等），增强模型能力，如拍照查，根据图片绘制表格、开发前端代码等任务。

配置应用请参见：
1.1 创建模型推理接入点。
2. 零代码智能体创建。
示例代码如下：

import os
from volcenginesdkarkruntime import Ark # 通过命令安装方舟SDK pip install 'volcengine-python-sdk[ark]'

# 初始化Ark客户端
client = Ark(
    base_url="https://ark.cn-beijing.volces.com/api/v3",    
    api_key=os.getenv('ARK_API_KEY'), # 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
)

print("----- standard request -----")
completion = client.bot_chat.completions.create(
    model="<YOUR_BOT_ID>",
    messages = [
        {
            "role": "user",  # 指定消息的角色为用户
            "content": [  # 消息内容列表    
                {
                    "type": "image_url",  # 图片消息
                    # 图片的URL，需要大模型进行理解的图片链接
                    "image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"}
                },
                {"type": "text", "text": "支持输入图片的模型系列是哪个？"},  # 文本消息
            ],
        }
    ],
)
print(completion.choices[0].message.content)
print(completion.references)

图文混排
支持灵活地传入提示词和图片信息的方式，您可以任意调整传图图片和文本的顺序，以及在system message或者User message传入图文信息。模型会根据顺序返回处理信息的结果，示例如下。

Curl
Python
Go
Java
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer $ARK_API_KEY" \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "system",
            "content": [
                {"type": "text", "text": "下面人物是目标人物"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/target.png"
                    }
                },
                {"type": "text", "text": "请确认下面图片中是否含有目标人物"}
            ]
        },
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "图片1中是否含有目标人物"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/scene_01.png"
                    }
                },
                {"type": "text", "text": "图片2中是否含有目标人物"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/scene_02.png"
                    }
                }
            ]
        }
    ],
    "max_tokens": 300
  }'
说明

图文混排场景，图片与文本顺序会影响模型输出效果，如果输入结果与预期不符，可以尝试更换图文和文本的顺序。
提示词支持图片和文字混排输入给模型，但图文顺序可能对模型的输出效果产生影响，特别是在图片较多且只有一段文字的情况下，建议拼接时将文字放在图片之后。


视觉定位（Visual Grounding）
请参见教程 视觉定位 Grounding。

GUI任务处理
请参见教程 GUI 任务处理。

最佳实践-深度思考模式
doubao-1-5-vision-pro-250328 模型，支持使用以下System Prompt，开启深度思考模型，并获得最佳效果。

You should first think about the reasoning process in the mind and then provide the user with the answer. The reasoning process is enclosed within <think> </think> tags, i.e. <think> reasoning process here </think>here answer
下面是简单回复示例。

模型回复说明
模型回复示例
通过System Prompt开启思考模型时，思考内容不会通过回复中的 reasoning_content 字段输出。思考内容与回答内容，均通过回复中的 content 字段输出。
例如：

<think>
思考内容
</think>
回答内容

最佳实践-上传本地图片进行分析
下面介绍具体场景的应用案例，包括数据处理以及模型调用等端到端的案例。
处理图片通常会与网络存储结合起来使用，下面介绍如何结合对象存储 TOS，来实现完整的图片处理流程。

代码流程
完整流程会分成以下步骤：

压缩图片。分辨率会影响 token 消耗数量，可以通过图片压缩，来节省网络、存储以及模型分析成本。
将压缩后的图片上传至对象存储 TOS，并为图片生成预签名 URL。
其中调用TOS需要使用Access Key，获取Access Key 请参见Access Key 签名鉴权。

调用视觉理解大模型分析图片。

示例代码
Python
Go
Java
安装依赖。

pip install -r requirements.txt
requirements.txt文本内容如下：

Pillow
volcengine-python-sdk[ark]
tos
示例代码。

import os
import tos
from PIL import Image
from tos import HttpMethodType
from volcenginesdkarkruntime import Ark

# 从环境变量获取 Access Key/API Key信息
ak = os.getenv('VOLC_ACCESSKEY')
sk = os.getenv('VOLC_SECRETKEY')
api_key = os.getenv('ARK_API_KEY')
# 配置视觉理解模型的 Model ID
model_id = '<MODEL>'

# 压缩前图片
original_file = "original_image.jpeg"
# 压缩后图片存放路径
compressed_file = "compressed_image.jpeg"
# 压缩的目标图片大小，300KB
target_size = 300 * 1024

# endpoint 和 region 填写Bucket 所在区域对应的Endpoint。
# 以华北2(北京)为例，region 填写 cn-beijing。
# 公网域名endpoint 填写 tos-cn-beijing.volces.com
endpoint, region = "tos-cn-beijing.volces.com", "cn-beijing"
# 对象桶名称
bucket_name = "demo-bucket-test"
# 对象名称，例如 images 下的 compressed_image.jpeg 文件，则填写为 images/compressed_image.jpeg
object_key = "images/compressed_image.jpeg"

def compress_image(input_path, output_path):
    img = Image.open(input_path)
    current_size = os.path.getsize(input_path)

    # 粗略的估计压缩质量，也可以从常量开始，逐步减小压缩质量，直到文件大小小于目标大小
    image_quality = int(float(target_size / current_size) * 100)
    img.save(output_path, optimize=True, quality=int(float(target_size / current_size) * 100))

    # 如果压缩后文件大小仍然大于目标大小，则继续压缩
    # 压缩质量递减，直到文件大小小于目标大小
    while os.path.getsize(output_path) > target_size:
        img = Image.open(output_path)
        image_quality -= 10
        if image_quality <= 0:
            break
        img.save(output_path, optimize=True, quality=image_quality)
    return image_quality

def upload_tos(filename, tos_endpoint, tos_region, tos_bucket_name, tos_object_key):
    # 创建 TosClientV2 对象，对桶和对象的操作都通过 TosClientV2 实现
    tos_client, inner_tos_client = tos.TosClientV2(ak, sk, tos_endpoint, tos_region), tos.TosClientV2(ak, sk,
                                                                                                      tos_endpoint,
                                                                                                      tos_region)
    try:
        # 将本地文件上传到目标桶中, filename为本地压缩后图片的完整路径
        tos_client.put_object_from_file(tos_bucket_name, tos_object_key, filename)
        # 获取上传后预签名的 url
        return inner_tos_client.pre_signed_url(HttpMethodType.Http_Method_Get, tos_bucket_name, tos_object_key)
    except Exception as e:
        if isinstance(e, tos.exceptions.TosClientError):
            # 操作失败，捕获客户端异常，一般情况为非法请求参数或网络异常
            print('fail with client error, message:{}, cause: {}'.format(e.message, e.cause))
        elif isinstance(e, tos.exceptions.TosServerError):
            # 操作失败，捕获服务端异常，可从返回信息中获取详细错误信息
            print('fail with server error, code: {}'.format(e.code))
            # request id 可定位具体问题，强烈建议日志中保存
            print('error with request id: {}'.format(e.request_id))
            print('error with message: {}'.format(e.message))
            print('error with http code: {}'.format(e.status_code))
        else:
            print('fail with unknown error: {}'.format(e))
        raise e


if __name__ == "__main__":
    print("----- 压缩图片 -----")
    quality = compress_image(original_file, compressed_file)
    print("Compressed Image Quality: {}".format(quality))

    print("----- 上传至TOS -----")
    pre_signed_url_output = upload_tos(compressed_file, endpoint, region, bucket_name, object_key)
    print("Pre-signed TOS URL: {}".format(pre_signed_url_output.signed_url))

    print("----- 传入图片调用视觉理解模型 -----")
    client = Ark(api_key=api_key)

    # 图片输入:
    completion = client.chat.completions.create(
        # 配置推理接入点
        model=model_id,
        messages=[
            {
                "role": "user",
                "content": [                    
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": pre_signed_url_output.signed_url
                        }
                    },
                    {"type": "text", "text": "Which is the most secure payment app according to Americans?"},
                ],
            }
        ],
    )

    print(completion.choices[0])

相关文档
对话(Chat) API：视觉理解 API 参数说明，调用模型的视觉理解能力，模型调用中出现错误，可参考视觉理解 API 参数说明。

常见问题
使用视觉理解模型时，报错InvalidParameter？

附1. 视频理解时间戳拼接工作原理
视频处理的核心方式为 “帧与时间戳的结构化拼接”，具体规则如下：

对视频抽帧得到的每帧图像，在其前插入时间戳文本，格式为 [<时间戳> second]。
拼接后形成“时间戳+图像”的有序序列，模型通过该序列理解视频的时序逻辑和内容变化。

抽帧逻辑举例
FPS 1

FPS 0.5

FPS 2

时间戳

[0.0 second]

[0.0 second]

[0.0 second]

视频帧

<IMAGE>

<IMAGE>

<IMAGE>

时间戳

[1.0 second]

[2.0 second]

[0.5 second]

视频帧

<IMAGE>

<IMAGE>

<IMAGE>

时间戳

[2.0 second]

[4.0 second]

[1.0 second]

视频帧

<IMAGE>

<IMAGE>

<IMAGE>

时间戳

[3.0 second]

[1.5 second]

视频帧

<IMAGE>

<IMAGE>

时间戳

[4.0 second]

[2.0 second]

视频帧

<IMAGE>

<IMAGE>

时间戳

[5.0 second]

[2.5 second]

视频帧

<IMAGE>

<IMAGE>

时间戳

[3.0 second]

视频帧

<IMAGE>

时间戳

[3.5 second]

视频帧

<IMAGE>

时间戳

[4.0 second]

视频帧

<IMAGE>

时间戳

[4.5 second]

视频帧

<IMAGE>

时间戳

[5.0 second]

视频帧

<IMAGE>

共6帧

共3帧

共11帧


多图请求等效
视频理解请求等效于下面示例的多图理解请求。

{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [
                {
                    "type":"text",
                    "text":"你觉得这个恐怖吗？"
                },
                {
                    "type":"text",
                    "text":"[0.0 second]"
                },
                {
                    "type":"image_url",
                    "image_url":{
                        "url":"https://ark-public.tos-cn-beijing.volces.com/80hou@0.jpg"}
                },
                {
                    "type":"text",
                    "text":"[1.0 second]"
                },
                {
                    "type":"image_url",
                    "image_url":{
                        "url":"https://ark-public.tos-cn-beijing.volces.com/80hou@1.jpg"}
                },
                {
                    "type":"text",
                    "text":"[2.0 second]"
                },
                {
                    "type":"image_url",
                    "image_url":{
                        "url":"https://ark-public.tos-cn-beijing.volces.com/80hou@2.jpg"}
                },
                {
                    "type":"text",
                    "text":"[3.0 second]"
                },
                {
                    "type":"image_url",
                    "image_url":{
                        "url":"https://ark-public.tos-cn-beijing.volces.com/80hou@3.jpg"}
                },
                {
                    "type":"text",
                    "text":"[4.0 second]"
                },
                {
                    "type":"image_url",
                    "image_url":{
                        "url":"https://ark-public.tos-cn-beijing.volces.com/80hou@4.jpg"}
                },
                {
                    "type":"text",
                    "text":"[5.0 second]"
                },
                {
                    "type":"image_url",
                    "image_url":{
                        "url":"https://ark-public.tos-cn-beijing.volces.com/80hou@5.jpg"}
                }
            ]
        }
    ]
}
上一篇
结构化输出
下一篇
视觉定位 Grounding
支持模型
前提条件
快速开始
使用说明
图片理解
图片传入方式
图片像素说明
图片数量说明
图片文件容量
token 用量说明
图片格式说明
API 参数字段说明
视频理解
时序信息
视频格式说明
视频文件容量
不支持音频理解
用量说明
使用示例
多图输入
Base64 编码输入
控制图片理解的精细度
通过 detail 字段（图片理解）
通过 image_pixel_limit 结构体
控制视频理解的精细度
感知视频时序
使用BotChatCompletions接口
图文混排
视觉定位（Visual Grounding）
GUI任务处理
最佳实践-深度思考模式
最佳实践-上传本地图片进行分析
代码流程
示例代码
相关文档
常见问题
附1. 视频理解时间戳拼接工作原理
抽帧逻辑举例
多图请求等效

全天候售后服务
7x24小时专业工程师品质服务

极速服务应答
秒级应答为业务保驾护航

客户价值为先
从服务价值到创造客户价值

全方位安全保障
打造一朵“透明可信”的云
logo
关于我们
为什么选火山
文档中心
联系我们
人才招聘
云信任中心
友情链接
产品
云服务器
GPU云服务器
机器学习平台
客户数据平台 VeCDP
飞连
视频直播
全部产品
解决方案
汽车行业
金融行业
文娱行业
医疗健康行业
传媒行业
智慧文旅
大消费
服务与支持
备案服务
服务咨询
建议与反馈
廉洁舞弊举报
举报平台
联系我们
业务咨询：service@volcengine.com
市场合作：marketing@volcengine.com
电话：400-850-0030
地址：北京市海淀区北三环西路甲18号院大钟寺广场1号楼

微信公众号

抖音号

视频号
© 北京火山引擎科技有限公司 2025 版权所有
代理域名注册服务机构：新网数码 商中在线
服务条款
隐私政策
更多协议

京公网安备11010802032137号
京ICP备20018813号-3
营业执照
增值电信业务经营许可证京B2-20202418，A2.B1.B2-20202637
网络文化经营许可证：京网文（2023）4872-140号